# 강의 구성과 활용 방법   

1. [파트별 강의 특징과 활용법](#1-파트별-강의-특징과-활용법)
    - [Part2. 유틸리티 강의](#part2-유틸리티-강의)
    - [Part3. 웹서비스와 데이터 기초](#part3-웹서비스와-데이터-기초)
    - [Part4. 서버 엔지니어링, Part5.Observability](#part4-서버-엔지니어링-part-5-observability)
    - [Part6. 분산 시스템 Fundamental](#part6-분산-시스템-fundamental)
    - [Part7. ElasticSearch(OpenSearch)](#part7-elasticsearchopensearch)
    - [Part8. Hadoop, Hive, HBase](#part8-hadoop-hive-hbase)
    - [Part9. Batch, ETL, Workflow Scheduler](#part9-batch-etl-workflow-scheduler)
    - [Part10. Distributed Streaming Processing](#part10-distributed-streaming-processing)
    - [Part11. Spark](#part11-spark)   
    - [Part12. BigData OLAP](#part12-bigdata-olap)
    - [Part13. 대용량 데이터 에코 시스템 구축하기](#part13-대용량-데이터-에코-시스템-구축하기)
    - [Part14. Engineer Way](#part14-engineer-way)
    
## 1. 파트별 강의 특징과 활용법  

### 난이도에 대한 기준   

![image](https://user-images.githubusercontent.com/92377162/230763069-33eabccb-8e3b-4688-a46c-44ab5495db44.png)   
- 소프트웨어 엔지니어링에서 만나게 되는 문제의 쉽고 어려움의 차이는, 대부분 익숙함의 차이 -> 반복해서 공부하는 것이 중요   

---   

### Part2. 유틸리티 강의   
   
- 강의 특징
    - 강의에서 다루는 기술을 사용하는데 기초가 되는 지식, 기초 기술 학습

- 활용방법
    - 클림명을 보고서 자신이 모르는 내용, 필요한 내용을 골라서 학습
    - 각 파트의 도입부에서 각 파트의 강의를 수강하려면 알아야할 유틸리티 강의 내용 언급 -> 찾아 학습   

        ![image](https://user-images.githubusercontent.com/92377162/230762675-07e9cae8-9002-44bf-9c14-b59bfc2d507a.png)

- 활용 예시
    - ex1. Java를 배운적이 있으면 들을 필요가 없음. 자바를 배운적이 있지만 Java 프로그램이 동작하는 JVM에 대해서는 살펴본적이 없다면, JVM 학습
    - ex2. Spark학습 시, 실무에서 Scala로 코드를 짤 일이 없다면 Scala는 듣지 않고, Java 또는 Python 버전으로 Spark Application을 작성하면서 강의를 학습
    - ex3. Python을 배운적이 없는데, Airflow 강의를 듣다보니 python을 몰라서 막힌다. 그런 경우에 Airflow강의를 시작전에 python 강의를 듣고 시작
    - ex4. Java로 프로그램을 짤 줄 안다. 하지만 maven만 사용해보고 gradle은 사용해본 적이 없다 이 경우에는 프로젝트를 진행하면서 강의에서 gradle로 진행하는 부분을 maven으로 바꾸어서 진행해도 됨
    - ex5. 이미 실무에서 AWS를 활용하고 있어서, AWS 사용방법이 익숙하다. 굳이 유틸리티 강의에서 AWS관련 내용은 듣지 않아도 됨.

---   

### Part3. 웹서비스와 데이터 기초   
  
- 강의내용
    - 강의 전체에서 다루는 예제를 이해하기 위해서, 웹서비스에서 어떤 데이터를 다루는지 이해한다.

- 강의특징 & 수강대상
    - 현재 데이터 엔지니어링은 웹이라는 환경 속에서 동작하는 기술이다. 웹에 대한 기초적인 이해가 없다면, 강의를 듣는 내내 답답할 것이다.
    - 이미 아는 분들도, 복습한다는 마인드 도는 혹시 내가 모르는 관점을 강사가 알려주지는 않을까 하는 기대감으로 들으면 좋겠다.
    - 특히 강의에서 진행할 예제, use case들에서 다루는 데이터에 대해서 기초적인 설명을 하는 부분은 이후 강의에서 다루는 예제에 대한 최소한의 합의점이므로 꼭 들어야 함

---   

### Part4. 서버 엔지니어링, Part 5. Observability 

> Server(Backend) Engineering 기초 : Data Engineering 기술은 기본적으로 서버사이드(백엔드) 기술을 포함한다. 데이터 엔지니어도 알아햐 하는 서버 엔지니어링에서의 기본적인 내용을 다룸. 데이터베이스는 추후 대용량 분석시스템을 이해하는 기초가 되기 때문에 심화된 내용까지 다룬다.   

> Observability는 백엔드, 데이터엔지니어링 상관없이 서버사이드 엔지니어링을 한다면 누구든지 알고 활용해야하는 부분이다.특히 데이터 엔지니어는 대용량 시스템을 다루다보니 Observability를 활용하는 능력이 무엇보다 중요함.   

- 강의내용 
    - 데이터를 관리하는 API 서버를 만들 수 있다.
    - 서비스를 외부에 런칭하기 위한, 인프라와 주변 시스템을 이해하고 세팅할 수 있다.
    - ELK로 간단한 로그 수집 파이프라인을 만들 수 있다.
    - 데이터 모델링의 기초를 배움
    - 서버 엔지니어가 아는 도구만으로 작은 규모의 분석환경을 세팅하는 법을 배운다.
    - 데이터 엔지니어가 모니터링해야하는 대상의 종류와 특징을 알 수 있다.
    - 자신이 원하는 메트릭을 정의, 수집, 시각화 할 수 있다.

- 강의특징 & 수강대상

> 데이터 엔지니어링 영역에서 굳이 다루지 않지만, 데이터 엔지니어라면 당연히 알고 할 줄 알아야 하는 내용이다. 강의의 제목과 강의자료(필수)를 훑어보았을 때 자신이 아는 내용이고 해본 적이 있다면 굳이 듣지 않아도 됨

> Observability 파트 안에 있는 내용 중 혹시 해보진 않고 들어본적만 있는 내용이 있다면, 실습을 꼭 해야 이후 데이터 엔지니어링에서 관련된 내용을 진행할 때 무리가 없음

> 데이터 베이스 구조와 동작 방식(MySQL을 기초로) 강의는 데이터 베이스가 동작하는 방식을 이론적으로 배우는 강의. 몰라도 실무에 큰 영향이 없지만, 실력있는 개발자와 그렇지 않은 개발자를 가르는 기준이 됨. 데이터 엔지니어는 일반 백엔드 엔지니어보다 데이터 베이스 종류를 더 잘 이해해야 제대로 시스템을 구축하고 운영할 수 있음. 뒤에 데이터 엔지니어링 파트에서는 이와 비슷한 성격의 강의가 분산시스템, 빅데이터와 같이 더 어려운 시스템을 대상으로 준비되어있음.

> 서버 엔지니어링 파트에서 '내가 스타트업의 데이터 엔지니어라면? - 가장 빠르게 작은 규모의 분석환경 세팅하기' 내용은 모든 수강생에게 도움이 되는 내용. 기술 스택 외에 엔지니어로서 요구사항 분석을 정확하게 하는 방법을 배울 수 있음. 유경험자라고 하더라도 자신의 설계와 의사결정을 되돌아보고 배우는 점이 있을 것.

> 엔지니어링 자체를 잘하면 기술 스택이 바뀌고, 유행이 바뀌고, 패러다임이 바뀌더라도 어디서나 인정받고 대우받는 엔지니어가 될 수 있음.

- Part4. 난이도 & Part5. 난이도   

    ![image](https://user-images.githubusercontent.com/92377162/230763395-c16b3ec8-ee11-4b98-8970-cb1c0c4a4582.png)

---

## Part6. 분산 시스템 Fundamental   

- 강의내용
    - 분산시스템의 기초 이론을 배운다.
    - 분산시스템에서 풀고자 하는 대표적인 문제와 해결방법을 배운다.
    - 분산시스템에서 많이 사용하는 zookeper(coordinator)의 원리와 활용방법을 배운다.

- 수강대상
    - 데이터 엔지니어로서의 기초를 쌓고 싶은 수강생
    - 특정 기술스택을 배우기 위해 강의를 듣는데, 시간이 없는 사람은 듣지 않아도 상관없음. Zookeper가 coordinator로 많이 사용되지만, 모르고 설치해도 웬만하면 잘 돈다. 이론에 관심없으면 Zookeeper 실습 부분만 학습   

    ![image](https://user-images.githubusercontent.com/92377162/230763610-31e0bab1-85d1-428c-94ef-6efe9b98c531.png)

---

## Part7. ElasticSearch(OpenSearch)   

- 강의내용
    - ElasticSearch의 구성과 동작원리를 이해한다.
    - 데이터 엔지니어 관점에서 ElasticSearch를 이해하고 활용한다.
    - ElasticSearch의 index를 관리하는 방법을 배운다.
    - ElasticSearch Cluster 구성방법을 배운다.
    - 중견 기업 규모의 데이터 분석환경을 빠르게 구성하는 방법을 배운다.

- 강의 특징
    - ElasticSearch(OpenSearch)에 관심이 없고, 사용할 일도 없다면 강의를 듣지 않아도 이후 강의 수강에 문제가 없다. 단, ElasticSearch의 기술과는 별개로 '중견 기업 규모의 데이터 분석환경을 빠르게 구성하는 방법', 'OpenSource Software와 기업관계 이해하기'은 들을 수 있다.
    - 'Lucene이 indexing하는 방법'은 이론에 관심없는 수강생은 듣지 않아도 상관없음
    - 'OpenSearch cluster 운영'에서부터 본격적으로 대용량 시스템을 운영하기 위한 기술을 배움
    - '중견 기업 규모의 데이터 분석환경을 빠르게 구성하는 방법'강의는 Part4에서 다룬 '내가 스타트업의 데이터 엔지니어라면? - 가장 빠르게 작은 규모의 분석환경 세팅하기'와 연결성이 있는 강의이다. 이것도 앞선 강의와 마찬가지로 모든 수강생이 들으면 좋을 강의이다. 요구사항을 분석하고, trade off를 고려해서 의사결정하는 방법을 배울 수 있다.
    - 'OpenSource Software와 기업관계 이해하기'는 썰푸는 시간이라고 생각하고 편하게 들으면 된다. 오픈소스에 대해서 비판적으로 생각하는 시각을 배울 수 있음
       
    ![image](https://user-images.githubusercontent.com/92377162/230764818-acb409c1-c00d-43b8-84df-06455e5cdfa9.png)

---

## Part8. Hadoop, Hive, HBase
- 강의내용
    - 대용량 데이터를 관리하는 대표 시스템인 Hadoop의 구성과 원리를 이용
    - Hadoop 환경을 위해 사용하는 대표 resource manager인 Yarn을 배움
    - Hadoop eco system의 대표 metadata store인 Hive를 배움
    - 대용량 NoSQL의 대표인 HBase를 배우고 활용한다.
    - 실제 서비스의 use-case로 활용한다.

- 강의특징 & 수강대상
    - 본격적으로 대용량 데이터를 다룬다.
    - Hadoop은 대용량 데이터를 다뤄야하는 업무라면 데이터 엔지니어가 필수적으로 알아야 하는 도구이니까 잘 배워두는 것이 좋다. 강의가 너무 어렵다면, 완강 후 반복하면 쉽게 느껴질 것이다.
    - 대기업의 Hadoop DBA수준으로 Hadoop 클러스터를 관리하는 방법은 배우지 않는다.
    - Hadoop은 오래되고 많은 양의 코드를 가지고 있어서, OpenSource 버전의 (Vanila) Hadoop을 잘 운영하면서 쓰기는 어려움. 본 강의는 AWS의 EMR 환경을 기본으로 설치하고 배움.
    - Hadoop Chapter 이후의 모든 강의에서 Hadoop을 사용하는 환경이나 예제가 등장한다. Hadoop을 세팅하지 않고 이후 강의의 실습을 진행할 수 없음
    - HBase에서는 대용량 데이터는 사용할 때도 이론적인 이해와 설계가 얼마나 중요한지 배울 수 있음
    - '언제 Hadoop을 쓰는게 좋을까?' 강의도 '중견 기업 규모의 데이터 분석환경을 빠르게 구성하는 방법' 강의에 이은 엔지니어링 설계와 의사결정 방법 강의이다. 데이터가 많아지면 하둡을 써야한대라는 편견을 갖고 있다면 필히 수강

---

## Part9. Batch, ETL, Workflow Scheduler
- 강의내용
    - 배치 처리 시스템의 역사를 배우고, 대표적인 방법을 배운다.
    - Workflow Scheduler의 대표인 airflow를 설치, 활용, 운영할 수 있다.

- 강의특징 & 수강대상
    - 전통적인 배치의 개념과 도구들로부터 Workflow Scheduler 역할까지 할 수 있는 Airflow까지 배움. 기술의 흐름을 이해할 수 있는 강의이다.
    - Airflow만 배우고 싶다면, 앞의 Cron, ETL 강의는 건너뛰어도 괜찮다.
    - Airflow 운영을 하는 것이 아니라 DAG 개발만 한다면, DAG 개발하고 운영하기, DAG 실습 1,2만 수강.   
       
    ![image](https://user-images.githubusercontent.com/92377162/230765905-8dd711c8-73ec-4ad7-9c82-2cea0b3f36b0.png)

---

## Part10. Distributed Streaming Processing
- 강의내용
    - 실시간 데이터 처리를 위한 시스템을 구성할 수 있다.
    - 분산 메세지 큐인 Kafka를 이해하고 활용할 수 있다.
    - 실시간 데이터 처리에서 중요한 기술적인 이슈를 이해하고, 비용과 해결방법을 제시할 수 있음
    - 실시간 데이터 처리 프레임워크의 기술의 한계와 극복 방법을 보고서 스트리밍 기술의 발전 흐름을 이해할 수 있음.

- 강의특징 & 수강방법
    - Kafka는 현대 분산시스템의 가장 대표적인 제품이다. 잘 이해해두면 가장 발전된 형태의 분산시스템의 주요 기술적인 특징들을 배울 수 있고, 이것은 다른 기술을 배우거나 사용할 때도 두고두고 유용하다. Kafka는 모르고 그냥 지나치면 안된다.

    - 대용량 데이터의 실시간 데이터 처리는 기업에서 Mission Critical하기 때문에 조심스럽기도 하고 운영하기도 어렵다. 실제 상용 서비스에서 실시간에서 겪는 어려움이 어떤 것이 있는지 자세하게 배울 수 있다. 이것을 잘 해결한다면 어느 회사를 가서든 대우받을 수 있다. 대신 실시간 처리는 장애에 민감하므로 삶은 피곤해질 수 있다. 물론 기술력으로 삶을 더 나아지게 하는게 엔지니어의 일이다.

    - 대용량 + 분산시스템이 만나면 코드보다 이론적인 것이 더 중요하다. 몇 줄 안되는 코드가 수백 수만대의 컴퓨터에서 돌아가기 때문이다. 여기서부터는 이론이 재미없고 어렵더라도 이해하려고 노력해야 함.

    - 꼭 기억해야할 것은 은총알은 없다. 단점을 극복하기 위해 나온 기술이라고 하더라도, 문제를 해결하기 위해서 생기는 단점(trade off)이 있다. 답을 배우는 강의가 아니라 과정을 배우는 강의이다.

    ![image](https://user-images.githubusercontent.com/92377162/230766273-4efa71d3-07a7-4230-881f-8282d46aae16.png)

---

## Part11. Spark
- 강의내용 
    - 분산 데이터 처리 프레임워크인 Spark의 개념을 이해하고 활용할 수 있음
    - Spark를 운영할 때 고려해야 할 점을 알고 대책을 마련할 수 있음
    - Spark로 배치, 실시간처리, 데이터 분석을 할 수 있음

- 강의특징 & 수강대상
    - Spark는 현재 단일 프레임워크로 데이터 분야에서 가장 많은 일을 할 수 있는 프레임워크이다. SparkSQL, DataFrame, DataSet 어떤 것으로 프로그래밍을 할 줄 안다면, 데이터 처리, 데이터 분석 모두 할 수 있다.
    - 본 강의는 Spark의 기능이나 Performance를 Deep Dive하는 강의는 아니다. 이부분이 필요하다면 Spark만 다루는 강의를 찾는 것이 더 좋을 수 있다.
    - Spark Application은 개발보다 운영이 더 어렵고 중요하다. 이 강의는 실무 수준의 운영이 가능하도록 이 내용을 자세히 다루었다.
    - 실습 코드에 대해서 강의자료에는 python 버전과 scala 버전의 코드를 담지만, 강의 촬영은 scala 버전으로만 진행한다.

    ![image](https://user-images.githubusercontent.com/92377162/230766415-6150fe0a-2fe2-45cc-b5a9-30671c8f14ad.png)

---

## Part12. BigData OLAP
- 강의내용
    - 대용량 데이터를 분석하기 위한 분석시스템을 구축할 수 있다.
    - 분석시스템의 장단점을 파악하고 선택할 수 있다.
    - Presto, Druid가 대용량 데이터를 어떻게 빠르게 조회할 수 있는지 배울 수 있다.

- 강의특징 & 수강대상
    - Presto, Druid 모두 설치만 잘 하면 웬만하면 알아서 좋은 성능을 낸다. 실제 다룰 데이터가 적고, 활용만 관심이 있다면 이론은 건너뛰어도 상관없음
    - 대용량 데이터의 indexing과 processing과 관련해서 구현가능한 가장 발전된 형태를 배울 수 있음
    - 앞에서 배운 RDBMS의 구조, Big Table 개념, Hadoop과 MR의 개념을 잘 배우고 이해한 수강생이라면, 이 강의에서 데이터 조회 시스템의 이해에 화룡정점에 다다를 것이다.

    ![image](https://user-images.githubusercontent.com/92377162/230767141-1dbc34a9-92da-47a3-90c7-7d0cf66890f3.png)

## Part13. 대용량 데이터 에코 시스템 구축하기
- 강의내용
    - 요구사항을 분석해서 대용량 데이터를 수집, 저장, 활용하는 아키텍처를 구성할 수 있다.
    - 분석시스템의 장단점을 파악하고 선택할 수 있다.
    - Data Warehouse, Data Lake, Data Mart의 개념을 학습하고, 지금까지 배운 시스템들을 이용해 아키텍처를 구성할 수 있다.
    - Lakehouse의 개념과 이론을 배우고, 현재 진행중인 오픈소스 프로젝트를 살펴본다.

- 강의특징
    - 내용적으로 앞의 강의의 모든 범위를 알지 못한다면 이해하기 어렵다.
    - 지금까지 배운 기술스택을 활용해서, 대기업의 전사 데이터 시스템 수준을 설계해보는 강의이다.
    - 이론으로만 진행되는 내용이고, 실제 구현은 너무 방대해서 강의에 담기 어려우므로 실습은 담지 않았다.
    - Lakehouse는 현재 활발히 논의되고 있는 최신 개념이고 상용제품으로 서비스되는 것들이 대부분이다보니, 시간이 지나면 내용이 정확하지 않을 수 있다. 대표 오픈소스의 개념적인 특징 중심으로 진행된다.

    ![image](https://user-images.githubusercontent.com/92377162/230767279-9473688b-388e-413a-a08f-3bfbbcd042e8.png)

---

## Part14. Engineer Way
- 강의특징
    - 개발자/엔지니어로 취업/성장하기 위한 방향을 제시해주는 강의
    - 뛰어난 엔지니어의 생각하는 방법
    - 강의를 잘 소화하고 앞으로 꾸준히 수련한다면, 기술의 팔로워가 아니라 기술의 리더가 될 수 있음