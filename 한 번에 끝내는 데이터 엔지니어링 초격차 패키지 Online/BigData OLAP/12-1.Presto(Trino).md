# Presto(Trino)

1. [Presto의 이해](#1-presto의-이해)
2. [Presto Architecture](#2-presto-architecture)
3. [Presto의 활용](#3-presto의-활용)
4. [Trino 실습](#4-Trino-실습)

---

## 1. Presto의 이해

### 1-1. Presto
- Presto 는 2013년에 Facebook 에서 opensource 로 공개한 PB 수준의 Hadoop 데이터에 대해서 SQL 쿼리가 가능한 분산 쿼리 엔진이다.
- Prestor가 있기 전 기존의 hive와 같은 시스템은 SQL을 Hadoop 에서 가능하게 했지만, 단일 머신 기반으로 동작하는 한계가 있었다. Presto는 대량의 데이터를 SQL로 조회하는데 있어서 확장성을 기반으로 더 빠르게 대량의 데이터에 대해 다양한 쿼리를 지원하기 위해 만들어졌다.
- Presto 의 활용도가 높아지면서 Hadoop 뿐만 아니라 여러 저장소를 Connector 라는 plugin 방식으로 연결해서 여러 데이터 시스템과의 연동을 SQL을 통해서 할 수 있도록 했다. 현재는 다양한 빅데이터 시스템의 쿼리 허브로도 쓰일 수 있게 되었다.
- 이는 Presto의 설계가 분산해서 데이터를 처리하는 아키텍처, query plan 과 execution model 의 추상화, 잘 설계된 connector 인터페이스를 통해서 가능했다.
- Presto 를 만들었던 주축 개발자들이 Facebook을 나와서 Trino 라는 프로젝트로 새롭게 개발하고 있다. 현재는 Presto 는 유지만 되고 있고, active 한 개발은 Trino 를 기준으로 되고 있다.

---

## 2. Presto Architecture

### 2-1. ServerTypes
- Presto는 하나의 coordinator와 여러개의 worker 서버가 클러스터를 이룬다.

<img width="500" alt="image" src="https://github.com/seonwook97/Data-Engineering/assets/92377162/bba6e68e-f152-493a-ad5a-214e6dc35697">

#### 2-1-1. Coordinator
- Coordinator 는 query 를 parsing, planning 하고, worker node 를 관리하는 역할을 한다. 설치 단계에서 Presto 의 brain 역할을 한다. 클라이언트는 coordinator 에게 statement를 제출한다.
- Presto Cluster 는 하나 이상의 worker 와 하나의 coordinator 가 있어야 한다. test 또는 dev 목적으로 사용한다면 하나의 노드로 coordinator, worker 역할을 모두 하게 할 수도 있다.
- coordinator 는 각 worker 의 활동을 트래킹하고 query 실행과 관련해서 로드를 조절한다. coordinator 는 query 를 실행하기 위한 logical 모델을 만든다. 이 logical 모델은 실행의 단위를 논리적으로 구분한 stage 들의 연결로 구성되어있다. 각 stage 는 실제 worker 에서 실행할 task 들로 구성되어있다.
- coordinator 는 worker 와 REST API로 통신한다.

#### 2-1-2. Worker
- Worker 는 task 실행하고 data 를 처리하는 서버이다. Worker 는 connector 로부터 데이터를 가져오고 중간 처리 데이터를 서로 교환한다. coordinator 는 worker 가 처리한 데이터를 가져와서 client 에게 리턴한다.
- Worker 는 시작할 때 cooridnator 의 discovery server 에게 자신을 등록해야 coordinator가 task 를 나눠줄 수 있다.
- Worker 는 다른 worker 들과 coordinator 사이에 REST API로 통신한다.

### 2-2. Data Sources
- Presto 는 여러 종류의 datasource 와 연결해서 presto sql 로 통합해서 조회할 수 있는 것이 장점이다. 다양한 데이터 소스와 연결하기 위한 data source 모델을 설명한다.

#### 2-2-1. Connector
- Connector는 Presto 와 Hive, RDBMS 등을 연결한다. database driver 와 비슷한 방식이라고 생각하면 쉽다. Connector 는 Presto’s SPI 의 구현체로서 datasource 가 달라지더라도 Presto 가 표준API 로 상호작용할 수 있도록 한다.
    - SPI : https://prestodb.io/docs/current/develop/spi-overview.html

- 기본 built-in connector
    - JMX : https://prestodb.io/docs/current/connector/jmx.html
    - Hive : https://prestodb.io/docs/current/connector/hive.html
    - TPCH : https://prestodb.io/docs/current/connector/tpch.html

- 모든 catalog 는 특별한 connector 와 연결되어있다. `connector.name` 으로 설정한 이름이 해당 connector 와 연결하는 catalog 의 이름이 된다. 같은 type 의 connector 라도 별도의 catalog로 두개 이상 접근하도록 설정할 수 있다. 예를 들어 hive cluster 가 두개라면 hive1, hive2 의 이름으로 catalog 로 만들 수 있다. 

- 이용 가능한 connectors
    - https://prestodb.io/docs/current/connector.html
    - https://trino.io/docs/current/connector.html

#### 2-2-2. Catalog
- Catalog는 schema와 connector의 datasource를 참조하고 있다.
- 예를 들어, JMX connector 를 통해서 JMX 정보에 접근하는 JMX catalog 를 설정할 수 있다. Presto 에 SQL 을 실행하면 하나 이상의 catalog 를 참고해서 데이터 소스에 접근한다.
- 새로운 table 을 Presto 에 만들때 catalog 의 root 부터 fully-qualified table name 을 사용한다.
- 예를 들어 `hive.test_data.test` 라는 table name 은 `hive` catalog 에 있는 `test_data` schema 의 `test` table 을 의미한다.
- catalog 들은 Presto config directory 의 properties 파일에 정의한다.

#### 2-2-3. Schema
- schema 는 table 을 구성하는 방법이다. catalog 와 schema 로 쿼리할 table 을 정의한다.
- schema 는 target datasource 의 데이터를 이해할 수 있는 schema 로 지정해야한다.
- hive, MySQL 의 경우는 대상 database의 table 정의 형식을 과 유사하다.

#### 2-2-4. Table
- Table 은 type 과 함께 선언된 named column 으로 구성된 unordered row 데이터의 set이다. 
- 일반적인 RDBMS 과 같다. source data 와 table 의 mapping 은 connector에 의해서 정의된다.

### 2-3. Query Execution Model
- Presto는 SQL statement 를 실행하고 statement 를 분산된 coordinator 와 worker 들에서 실행할 수 있는 쿼리들로 변환한다.

#### 2-3-1. Statement
- Presto 는 ANSI-compatible SQL statements 를 실행한다.
- Presto 에서 말하는 Statement는 단순히 SQL statement 를 표현한 글자를 의미하고, query plan 에 의해서 만들어진 query 가 실제로 분산된 worker 에서 수행할 query 가 된다.

#### 2-3-2. Query
- Presto 는 client 로부터 받은 statement 를 parsing 하고 query 로 변환한다. 이 때 distributed query plan 도 생성한다. distributed query plan 은 Presto worker 들 에서 수행할 서로 연결된 stage 들로 실제로 실행되게 된다. query 의 생성에는 그 시점에 query 수행과 결과에 필요한 연관된 컴포넌트들 (connector, catalog, schema, table 등)의 snaphost 정보도 함께 포함되어있다.

- Statement와 query의 차이는 statement는 Presto에 전달된 SQL text인 반면에, query는 stages, tasks, splits, connectors 및 결과를 생성하기 위해 함께 작업하는 다른 구성 요소 및 데이터 소스를 포함한다. 

#### 2-3-3. Statement vs Query

![image](https://github.com/seonwook97/Data-Engineering/assets/92377162/a69edac2-641b-4cac-ba61-4a8df9c9ae78)

#### 2-3-4. Stage
- Presto가 query를 수행할 할 때 실행을 stage 들의 hierarchy 로 쪼갠 후 stage 별로 수행한다.
- query를 구성하는 stage의 hierarchy은 tree와 유사하다. 모든 query에는 다른 stage의 출력을 집계하는 root stage가 있습니다. stage는 coordinator가 분산 쿼리 계획을 모델링하는 데 사용하는 것이지만 단계 자체는 Presto worker에서 실행되지 않는다.

#### 2-3-5. Task
- 위에서 언급한 것처럼 logical plan 과 stage 자체는 실행되는 단위가 아니라 쿼리 실행에 대
한 논리적인 구분이다. stage 는 분산된 환경의 presto worker 가 수행할 task 의 집합으로 구현된다.
- Task 는 input 과 output 를 가지고, 하나의 stage 내의 일련의 task 들은 병렬로 수행될 수 있다.

#### 2-3-6. Split
- 태스크는 더 큰 데이터 세트의 섹션인 splits에서 작동한다. 분산 쿼리 계획의 가장 낮은 수준
의 stage는 커넥터에서 splits 을 통해 데이터를 조회하고, 더 높은 수준의 분산 쿼리 계획의
중간 stage는 다른 stage에서 데이터를 조회한다.
- Presto 가 query 를 스케줄링 하면, coordinator 는 하나의 table 에 모든 splits 의 리스트를
connector 에 query 한다. coordinator 는 어떤 머신에서 어떤 task 들이 동작하고 있는지,
어떤 task 가 어떤 split 을 처리하고 있는지 트래킹 한다.

#### 2-3-7. Stage - Task - Split

![image](https://github.com/seonwook97/Data-Engineering/assets/92377162/d9b570ec-8f67-48d9-baf6-54a6c764547e)

#### 2-3-8. Driver
- task 는 하나 이상의 병렬 드라이버를 가지고 있다. Driver 는 실제로 데이터를 가져오고, operator 들을 결합해서 ouput 을 내보낸다. Driver 는 operator instance 의 sequence 이다. Driver 는 Presto 의 parllelism archiecture 에서 가장 낮은 단계에 해당된다. 하나의 driver 는 하나의 input 과 하나의 output 을 가진다.

#### 2-3-9. Operator
- 하나의 operator 는 데이터를 가져오고 변환하고 내보낸다. 예를들어 table scan 은 connector 로부터 데이터를 가져오고, 다른 operator 로 데이터를 내보낸다. filter operator는 데이터를 가져오고, predicate 를 통과한 데이터만 내보낸다.

#### 2-3-10. Exchange
- exchange 는 query 의 다른 stage 에 데이터 전달을 위해 presto node 사이에 데이터를 전달한다. Task 는 데ouput 데이터를 output buffer 에 쓰고, 다른 task 는 exchange client를 이용해서 해당 버퍼에서 데이터를 읽어간다.

### 2-4. 정리

![image](https://github.com/seonwook97/Data-Engineering/assets/92377162/56135dc5-1bbf-42db-9349-93f3ce55a7a2)

![image](https://github.com/seonwook97/Data-Engineering/assets/92377162/a8603507-0812-4a02-9968-1200cb9c0a24)

---

## 3. Presto의 활용

### 3-1. Presto의 장점
1. ad-hoc 쿼리에 대해서 sub-seconds 또는 수분내에 응답이 가능하다. (데이터 사이즈나 리소스 제한에 따라 다를 수 있음)
2. 쿼리 수행이 빠르다.
    a. Disk I/O가 없다.
    b. pipelined execution model ( not map-reduce)
    c. compile a query plan down to byte code
    d. off heap memory
    e. Hive 보다 10배 이상 빠르다
3. 여러 데이터 소스를 지원한다. Hive, Kafka, MySQL, MonogoDB, Redis, JMX 등
    a. 이용 가능한 connectors
    - https://prestodb.io/docs/current/connector.html
    - https://trino.io/docs/current/connector.html
4. SPI 인터페이스에 맞추어서 직접 connector 를 만들 수 있다.
5. HTTP+JSON 기반으로 여러 언어로 쉽게 client 를 만들 수 있다.
6. JDBC/ODBC 연결을 지원한다.
7. ANSI SQL 을 지원한다.
8. 복잡한 연산을 위한 유용한 함수들이 많다. 
    - ref. functions : https://prestodb.io/docs/current/functions.html

### 3-2. Presto의 한계
- No fault tolerance
    - 분산된 worker에서 쿼리 수행시 하나의 worker 에서 실행에 실패하면 query 전체가 실패한다. retry 메커니즘 또한 없다.
- SPOF coordinator
    - Coordinator 는 하나만 존재하고 HA 가 불가능하다.
        - HA 를 직접 구현하는 경우가 대부분이고(사례), 기본 기능으로는 아직 개발이 완료되지 않았다.
- Memory Limitations for aggregations, huge joins
    - In-memory only 이기 떄문에 나타남.
    - No grace / hybrid hash join
    - multi table join, 특히 서로 다른 catalog, connector 에 대한 join 이 일어날때 메모리의 한계 때문에 불가능해지는 경우가 있다. (최신 버전에서는 disk 에 쓰는 operation 을 지원한다, 다만 이 경우에는 속도가 많이 느려진다.)
- MPP (Massively Parallel Processing) architecture
- MPP 아키텍처 자체는 단점이라고 할 수는 없다. 하지만 MPP 구조에서는 특정 datasource 의 응답이 느리다면 그것 때문에 쿼리 전체가 느려진다. 원본(downstream) 데이터 소스에서 읽어오는 성능 자체는  Presto 의 권한 밖이기 때문에 MPP 아키텍처로인해 Presto(upstream)의 성능이 영향받는다는 것은 한계점이 된다.
- No cost-based optimization
    - 이것 또한 MPP이기 때문에 발생한다. 원본 데이터를 읽어오는 것은 data source의 아키텍처나 성능 등에 달려있기 때문이다.

### 3-3. Presto 의 활용
- Presto 의 구축을 선택하는 가장 주요한 장점으로는 SQL로 ad-hoc query 를 수행하기에 좋다는 점과 다양한 datasource 를 지원하는 것에 있다. 하지만 ad-hoc query 용도로만 적합하다는 것이 한계가 된다. 따라서 다음과 같은 목적이나 활용도로 Presto 를 구축하고 사용하는 것이 적절하다.

1. 분석용 데이터, 특히 외부로 나가는 production 용 데이터 분석 보다는 내부용 데이터
분석에 활용한다.

2. 다양한 datasource 를 한 번의 SQL로 통합해서 조회하고 싶다.

---

## 4. Trino 실습
