# RDBMS 구조와 동작 방식

1. [RDBMS Architecture](#1-rdbms-architecture)
2. [MySQL Architecture](#2-mysql-architecture)
3. [InnoDB 스토리지 엔진 아키텍처](#3-innodb-스토리지-엔진-아키텍처)
4. [Indexing](#4-indexing)
5. [MySQL High Availability](#5-mysql-high-availability)

---

## 1. RDBMS Architecture

### 1-1. RDBMS의 아키텍처와 구성요소

#### 1-1-1. Overview
- 참고: https://dsf.berkeley.edu/papers/fntdb07-architecture.pdf

![image](https://user-images.githubusercontent.com/92377162/233919075-e885c58c-de85-458a-9106-4fb98fec8e8a.png)

#### 1-1-2. Client Communication Manager
- 외부의 Client 에서 접속하고, 명령을 전달할 수 있는 통로. 그리고 그 자원의 관리.
- Client 로부터의 연결을 받는다
    - 연결을 맺기 위한 인증, 보안 등의 프로세스를 처리한다.
- Client의 연결의 상태를 관리한다. (session)
- SQL의 실행 결과를 응답한다.

#### 1-1-3. Process Manager
- RDBMS에서 필요한 자원을 관리, 주로 프로세스/스레드의 전용, 스케줄링, 할당 등을 관리.
- Client에서 요청와서 연결을 맺으면 스레드에 할당된다. 이 때 Process Manager 는 Client connection pool 에서 유휴 스레드를 꺼내서 할당한다.
- 뿐만 아니라 read, write 등의 전용 스레드 풀도 따로 관리해서, 특정 작업의 부하나 병목 때문에 다른 작업을 할 자원이 부족한 일이 없게 한다.
- 실행을 즉시 할지, 지연해서 할지 등의 결정도 할 수 있다.

#### 1-1-4. Relational Query Processor
- Client 로부터 전달된 쿼리의 해석과 실행 계획을 담당.
- Query Parser가 Query 를 파싱한다.
- 접속한 유저가 해당 Query를 실행할 권한이 있는지 확인한다.
- Query optimizer가 적은 비용으로 쿼리를 실행 할 수 있도록, Query의 실행계획을 짠다. 이때 DBMS의 카탈로그 정보를 참고한다.
- Query Excecutor는 Query Plan 이 나오면 실제 물리적인 자원에 어떻게 할당할 것인지 결정한다.
- 그 외에도 부가적인 처리를 할 수 있다.
- Query Parser의 동작

    ![image](https://user-images.githubusercontent.com/92377162/233919817-cf1acabd-3a2a-4e42-bcbd-a5c41a5fb3bb.png)

- 문법을 확인한다.
- 구문의 내용의 의미를 확인한다.
    - table 의 존재여부
    - column 의 존재여부
- 자원을 많이 소모하는 작업을 피하기 위한 shared pool check를 한다. 이미 있는 내용이라면, 이후 자원을 많이 소모하면서 실행계획을 짜거나 실행할 필요가 없다.
- Query Optimizer의 동작방식

    ![image](https://user-images.githubusercontent.com/92377162/233920100-bb280f36-de8e-4c70-9df1-fe6b1b3a5006.png)

- SQL의 기능은 똑같지만, SQL문의 내용의 순서나 형식 등을 바꿔서 성능상 더 나은 쿼리가 나온다면, Query Transformer에서 query를 rewrite 한다.

    ![image](https://user-images.githubusercontent.com/92377162/233920257-7c382e30-5318-4581-a47e-d9012a2263a9.png)

- Estimator 는 실행 계획에 대한 비용을 계산한다. 이때 Data dictionary를 참고한다.
    - (Oracle 의 경우)다음 지표들을 수집/계산한다.
    - Selectivity: scan한 row중에 몇 퍼센트만큼 최종결과에 선택되는지 비율을 계산한다.
    - Cardinality: 각 플랜이 리턴한 결과의 row수.
    - Cost: 해당 작업이 얼마만큼의 리소스를 사용할지예 대한 추정치. 통계를 활용하고, 통계는 지속적으로 조정된다.

#### 1-1-5. Transactional Storage Manager
- Transaction 처리와 관련된 기능들을 담당.
- 실제 데이터에 접근
- Access method는 query 실행 오퍼레이터에 의해 원본데이터에서 뽑아낸 result tuple 을 리턴한다.
- Result tuple 은 만들어지면 buffer 에 위치한다. Client Manager는 이 버퍼에서 데이터를 가져와서 응답한다.
- Transaction 의 상태 기록, 라이프사이클 관리.

#### 1-1-6. Shared Components and Utilities
- 그 외에도 시스템의 각 기능이 잘 동작하기위해서 필요한 컴포넌트나 ,유틸들이 있다.

---

## 2. MySQL Architecture

### 2-1. MySQL Basic Architecture

#### 2-1-1. Overview
- MySQL 서버의 내부 구조

    ![image](https://user-images.githubusercontent.com/92377162/233922109-88b541fa-316f-4f7f-8630-a1c0679857ef.png)

#### 2-1-2. MySQL Engine
- MySQL Engine은 클라언트로부터의 요청을 받고, SQL을 분석하고 최적화하는 역할을 수행한다.
- Connection Handler
    - 클라이언트로부터의 접속, 쿼리요청 처리
- SQL interface
    - SQL을 받아준다.
- SQL Parser
    - SQL을 파싱하고, 전처리를 한다.
- SQL Optimizer
    - 쿼리 최적화와 실행계획을 짠다.

#### 2-1-3. Storage Engine
- MySQL Storage Engine은 실제 데이터를 디스크에 저장하거나, 디스크로부터 데이터를 읽는 처리를 담당한다.
- Storage Engine 은 Plugin 방식으로 원하는 구현체를 선택할 수 있다. 즉, 하나의 DB 서버에서 논리적으로 Storage Engine을 선택할 수 있다. 선택은 database , table 마다 할 수 있다. create database, table 선언시에 `ENGINE=$ENGINE_NAME` 으로 설정한다.
- `SHOW ENGINES;` 커맨드로 확인할 수 있다.
- MySQL 은 storage engine 뿐만 아니라 다양한 기능들도 플러그인 형태로 지원한다. 인증 관련 기능, 검색용 파서, 쿼리 rewrite 플러그인 등이 있다. 기본적으로 MySQL의 표준 API 가 열려있기 때문에 가능하다.

#### 2-1-4. Handler API
- MySQL엔진의 Query Executor 가 실제 데이터를 읽거나 쓸때, Storage Engine에 요청할 때 표준인터페이스인 handler API를 통해 한다. 즉, 각 storage engine 은 구현할 때 handler API 명세를 따라 구현되어 있다. 이 표준인터페이스 때문에 플러그인 방식으로 원하는 것을 선택할 수 있다.

### 2-2. MySQL 스레드 구조

#### 2-2-1. Overview

![image](https://user-images.githubusercontent.com/92377162/233923745-f2d562af-e4f9-44b5-8acf-eb50a6244989.png)

- MySQL 은 멀티 프로세스가 아니라 멀티 스레드 기반으로 동작한다. 동작 방식에 따라 Foreground, Backgound 스레드로 구분한다. 실행중인 스레드는 performance_schema 데이터베이스 > threads 테이블에 기록된다.

#### 2-2-2. Foreground Thread(Client connection)
- foreground thread 는 최소한 현재 연결된 클라이언트의 수만큼 존재한다. 클라이언트의 커넥션이 종료되면, 다시 스레드 캐시로 돌아간다. 스레드 캐시에 일정 개수 이상의 스레드가 대기중이라면, 스레드 캐시에 돌아가지 않고, 스레드를 종료한다. 최대 대기 스레드수는 `thread_cache_size` 로 설정한다.
- foreground thread 는 데이터를 데이터 버퍼나 캐시로부터 가져오고, 버퍼나 캐시에 없다면 디스크에서 읽어서 가져온다. InnoDB는 foreground thread 는 cache, buffer 까지만 접근하고 디스크에는 접근하지 않는다. 

#### 2-2-3. Background Thread
- InnoDB 기준으로 background thread 는 다음 일을 한다.
    - insert buffer 를 merge
    - Log 를 disk에 기록
    - InnoDB buffer pool의 데이터를 disk에 기록
    - 데이터를 버퍼로 read
    - Lock monitoring thread
- 원하는 읽기 쓰기 성능이 안나오거나, 주 사용용도를 예측해서 스레드 수를 조정할 수 있다.
    - `innodb_write_io_threads`
    - `innodb_read_io_threads`
    - innodb 의 경우 읽기는 대부분 포그라운드 스레드에서 처리되기 때문에 innodb의 read 스레드를 늘릴일은 많지 않다. 쓰기 작업이 많거나, 지연되는 경우에 `innodb_write_io_threads` 를 2 이상으로 세팅한다.
- innodb는 지연된 쓰기 작업을 지원한다. 쓰기 작업을 버퍼에 넣고 아직 디스크에 쓰이기 전에 클라이언트에 응답할 수 있다. 버퍼에 쌓인것은 내부적으로 배치처리로 적용한다.

### 2-3. 메모리 구조

![image](https://user-images.githubusercontent.com/92377162/233924865-8d1bc788-730a-4bd9-9465-e385037bdb4c.png)

#### 2-3-1. 글로벌 메모리 영역
- MySQL이 시작되면서 운영체제로 부터 할당 된다. 클라이언트 스레드 수와 상관없이 하나(또는 N개)의 공간이다. 모든 스레드가 공유하는 자원이다.
- 다음과 같은 내용들이 있다.
    - InnoDB buffer pool
    - InnoDB adaptive hash index
    - InnoDB redo log buffer
    - table cache

#### 2-3-2. 세션(로컬) 메모리 영역
- 클라이언트 스레드가 쿼리를 처리하는데 사용하는 메모리 영역. 각 클라이언트 스레드별로 독립적으로 할당 되고 공유되지 않는다. 각 쿼리별로 필요한 용량을 할당한다. 할당하지 않는 경우도 있다.
- Sort buffer
    - Sort 쿼리가 있을 때만 할당되고 해제된다. 아예 할당이 안될수도 있다.
- Join buffer
    - Join 쿼리가 있을 때만 할당되고 해제된다. 아예 할당이 안될수도 있다.
- Binary Log Cache
- Network buffer
    - Connection buffer는 항상 할당되어있다.

### 2-4. Query 실행 구조

![image](https://user-images.githubusercontent.com/92377162/233932441-939612cf-2768-4a8c-8cfb-6440a3a02381.png)

#### 2-4-1. Query Parser
- 쿼리를 토큰(인식할 수 있는 최소단위의 단어, 기호) 단위로 분리해 Tree 자료구조를 만든다. 문법 오류를 이 단계에서 검출한다.

#### 2-4-2. Preprocessor
- Parser Tree 를 기반으로 쿼리문 안에 의미적인 오류가 있는지 확인한다. 테이블 이름, 칼럼 이름, 내장함수와의 매핑 등을 확인한다.
- SQL 수행할 권한이 있는지 확인한다.

#### 2-4-3. Optimizer
- 쿼리를 가장 적은 비용(cost)으로 처리할 수 있도록 의사결정을 한다.
- 고려요소(파라미터)
    - 테이블, 또는 인덱스 당 page 수
    - 인덱스의 카디널리티
    - Row 길이
    - key 길이
    - key 분포

#### 2-4-4. Execution Engine
- 실행엔진은 Optimizer에게 받은 계획에 따라 핸들러에게 구체적으로 할 일(read, write)을 알려준다.
    - 예: group by 를 처리하기 위해 임시테이블을 만든다.
        1. Execution Engine이 핸들러에게 임시 테이블을 만들라고 요청
        2. Execution Engine은 where 에 일치하는 레코드를 읽어오라고 함.
        3. 읽어온 레코드를 1번에서 준비한 임시테이블에 저장하라고 핸들러에 요청
        4. 데이터가 준비된 임시 테이블에서 데이터를 읽으라는 요청을 핸들러에게 요청
        5. Execution Engine은 최종 결과를 사용자나 다른 모듈로 넘긴다.

#### 2-4-5. Handler (Storage Engine)
- Execution Engine의 요청에 따라 데이터를 디스크로 저장, 또는 데이터를 디스크에서 읽어오는 역할을 한다.

### 2-5. Query Cache
- SQL의 실행 결과를 메모리에 저장하고, 동일한 SQL이 실행되면 디스크에서 읽지 않고 즉시 결과를 준다. 다만, 테이블의 데이터가 변경되면 해당 테이블과 관련된 캐시를 모두 삭제 해야했는데, 이것 때문에 오히려 성능저하가 오는 경우가 많았다. 이 때문에 MySQL 8.0 에서 Query Cache는 삭제되었다.

### 2-6. Thread Pool 

![image](https://user-images.githubusercontent.com/92377162/233933540-a8998b32-7c8e-4a3b-9e98-6eaa9d364d01.png)

- 참고 : https://www.percona.com/software/mysql-database/percona-server

- Percona Server 의 스레드 풀은 기본으로 장치의 CPU 코어 수 만큼 스레드 그룹을 생성한다. `thread_pool_size` 로 조정할 수 있다. 다만, CPU 코어 수와 스레드 수를 맞추는 것이 Context Switch 가 덜 일어나므로 processor affinity 에 좋다. 이미 스레드 풀이 모두 일하고 있다면 `thread_pool_oversubscribe` 의 수만큼 추가로 스케줄링 할 수는 있다.

- 스레드 그룹의 모든 스레드가 할당되어 일하고 있다면, 스레드 풀은 스레드 그룹에 새로운 스레드를 추가할지, 아니면 기존 스레드가 작업을 완료할 때까지 기다릴지를 판단한다. 스레드풀의 타이머 스레드가 주기적으로 스레드 그룹의 상태를 체크해서 `thread_pool_stall_limit` 시스템 변수에 정의된  (milliseconds) 기간동안 작업을 못 끝낸다면, 새로운 worker thread를 추가한다.
    - client의 동시요청이 많고, 응답시간이 중요한 서비스라면?

- Percona Server의 스레드풀 플러그인은 선순위 큐와 후순위 큐를 이용해 특정 트랜잭션이나 쿼리를 우선 처리할 수 있는 옵션을 제공한다. 우선순위 큐에 속한 트랜잭션을 빨리 처리하면, 해당 transaction에 의한 lock이 빨리 해제되고, race condition을 낮추어서 전체적인 처리 성능을 높이자는 아이디어이다.

---

## 3. InnoDB 스토리지 엔진 아키텍처

### 3-1. InnoDB Architecture Overview

![image](https://user-images.githubusercontent.com/92377162/235339408-ddc87127-c212-4338-bb07-7d708330eae3.png)

- InnoDB는 가장 많이 사용되는 Storage Engine이다. MySQL의 스토리지 엔진 중 거의 유일하게 레코드 기반 Lock을 제공하고, 이 때문에 높은 동시성 처리가 가능하기 때문이다.

### 3-2. Clustering by Primary Key
- InnoDB의 모든 테이블은 기본으로 PK를 기준으로 클러스터링 되어 저장된다. PK값의 순서대로 디스크에 존재한다고 이해하면 된다. PK이외의 인덱스는 레코드의 주소 대신 PK값을 논리적인 주소로 사용한다. 따라서 PK를 기준으로 하는 Range Scan의 속도가 빠르다. 따라서 쿼리 실행 계획에서 PK는 다른 인덱스에 비해 비중이 높게 설정된다.
- myISAM 스토리지 엔진은 클러스터링 키를 지원하지 않는다. 따라서 MyISAM에서는 PK와 다른 인덱스 사이의 차이가 없다.

### 3-3. Foreign Key
- InnoDB에서 외래 키(Foreign Key)는 부모 테이블과 자식 테이블 모두 해당 칼럼에 대해 인덱스 생성이 필요하다. 또한 변경시 반드시 부모 테이블, 자식 테이블에 데이터가 있는지 체크하기 때문에 Lock이 여러 테이블로 전파 된다. 이 때문에 데드락이 발생할 위험이 있다.
    - `SET foreign_key_check=OFF;` 설정하면 체크 작업을 멈출 수 있다.

### 3-4. MVCC(Multi Version Concurrency Control)
- 레코드 레벨의 트랜잭션을 지원하는 DB에서 지원하는 기능이다. MVCC의 목적은 일관된 읽기를 제공하는 데 있다. InnoDB는 undo log를 이용해서 이 기능을 구현한다.

#### 3-4-1. MVCC 예제

![image](https://user-images.githubusercontent.com/92377162/235339542-5b82ef6b-a6b7-4d21-9cd3-16c84a22ad77.png)

- 다음 상태에서 `UPDATE member SET m_area='경기' WHERE m_id=12;` 를 수행하면 다음과 같은 상태로 변경된다.

![image](https://user-images.githubusercontent.com/92377162/235339556-360e2d62-617e-43da-8d11-dccc78de8bf6.png)

- 이 상태에서 만약 Isolation Level이
    - READ_UNCOMMITTED 라면, InnoDB 버퍼풀의 내용을 전달한다.
    - READ_COMMITTED 이상(REPEATABLE_READ, SERIALIZABLE)이라면, 아직 커밋되지 않았으므로 undo log의 내용을 반환한다.
- 즉, undo 영역으로 응답할 수 있기 때문에 동시에 두개의 버전이 존재할 수 있는데, 이것을 MVCC라고 한다. 다만, 사용이 복잡해질수록, undo space의 공간이 많이 필요할 수 있다.
- 여기서 commit이 일어나면 undo log는 없어지고, 버퍼풀의 내용이 디스크에 쓰인다. 다만, 디스크에 쓰이는 시점은 background thread에 의해 결정된다.
- 여기서 rollback이 일어나면 buffer cache에 undo log가 적용되고, undo log는 지워진다.

#### 3-4-2. 잠금 없는 일관된 읽기(non-locking consistent read)
- 위의 MVCC에 의해서 Lock을 걸지 않고 읽기 작업을 수행한다.
    - Serializable이 아니면서, 순수한 select문의 경우 (insert등과 연결되지 않은 트랜잭션)
- 단, Transaction이 시작되고 commit,rollback없이 오랜시간이 지나면 해당 트랜잭션으로 인해 undo log를 지우지 못하게 된다. 이것 때문에 서버거 느려지거나 undo log 공간부족으로 문제가 생길 수도 있다.

### 3-5. InnoDB 버퍼 풀
- 디스크의 데이터 파일이나 인덱스 정보를 메모리에 캐시하는 공간이다. 또한 쓰기 작업을 지연시키고 배치로 disk에 write 할 수 있도록 하는 버퍼 역할도 한다.
    - 예를 들어, insert, update, delete 요청을 다양하게 날린다면, 디스크에 random access를 높여 성능이 떨어진다. buffer pool이 이 작업들을 모아서 처리하면 random access 횟수를 줄일 수 있다.

#### 3-5-1. 버퍼풀 크기 설정
- 버퍼풀의 크기를 운영중 동적으로 조정할 수 있다.
    - `innodb_buffer_pool_size` 로 조정
- InnoDB의 버퍼풀은 해당 머신의 50%이하부터 시작해서 모니터링 하면서 늘려가는 방법을 추천한다. 쿼리의 결과가 대량의 레코드인 경우가 거의 없다면(client가 사용하는 record buffer 사이즈를 고려), 수정 없이 80%로 운영하는 것도 하나의 방법이다.
- 단, 버퍼풀의 메모리를 늘리는 것은 큰 문제가 없지만, 줄이는 것은 영향이 크므로 가능하면 줄이는 일이 없도록 운영해야한다.
- 버퍼풀은 내부적으로 세마포어로 잠근 경합이 있는데, 이 경합을 줄이기 위해 쪼개서 관리할 수 있다.
`innodb_buffer_pool_instances` 로 조정할 수 있다. 1GB 미만에 대해서는 1개만 가능하다. 버퍼풀 인스턴스당 5GB 정도가 되도록 유지하는 것이 적절하다.

#### 3-5-2. InnoDB 버퍼풀 구조
- InnoDB 스토리지 엔진은 버퍼풀을 page 조각 단위로 관리한다. (`innodb_page_size`, 보통 4K)
- 페이지 관리를 위해 LRU(least recently used), Flush, Free 세개의 자료구조로 관리한다.
    - LRU list: 한 번 읽어온 페이지를 최대한 오래 버퍼풀에 유지해서 hit를 높이고 disk access를 줄이기 위해 사용.
    - 내부적으로 두개의 리스트가 있는데, old 영역은 LRU(least recently used)로 관리, new 영역은 MRU(Most recently used)로 관리.
- Flush list: 디스크로 동기화되지 않은 데이터를 가진 페이지(dirty page)의 변경 시점 기준의 페이지 목록을 관리한다. 디스크에서 읽은 상태에서 변경이 가해지면 flush list 에의 해 관리. 특정 시점이 되면 disk에 기록된다.
- Free list: 비어있는 페이지 목록

#### 3-5-3. InnoDB에서 데이터를 찾는 과정
1. 필요한 레코드가 버퍼 풀에 있는지 검사
    a. InnoDB adaptive hash index를 통해 검색
    b. 해당 테이블의 인덱스(B-Tree)로 버퍼풀에서 페이지 검색
    c. 조회하려는 데이터의 페이지가 이미 버퍼 풀에 있었다면, 해당 페이지의 포인터를 MRU 방향으로 승급
2. (1에서 조회가 안되면)디스크에서 필요한 데이터 페이지를 찾아 버퍼풀에 적재, 적재된 페이지에 대한 포인터를 LRU head에 추가.
3. 버퍼풀의 LRU 헤더에 적재된 데이터 페이지가 읽히면, MRU 헤더로 이동.
4. 버퍼 풀에 상주하는 데이터 페이지는 사용자 쿼리가 얼마나 최근에 access 했는지에 따라 age가 부여됨. aging 이 오래되면 버퍼풀에서 제거된다. 버퍼 풀의 데이터 페이지가 access되면 age가 초기화되고, MRU의 헤더로 옮겨진다.
5. 필요한 데이터가 자주 접근된 데이터라면, 해당 페이지의 인덱스 키를 adaptive hash index에 추가

### 3-6. Change Buffer
- 변경해야할 인덱스 페이지가 버퍼풀에 있으면 바로 업데이트를 수행한다. 만약 디스크에서 읽어와서 업데이트를 해야한다면, 즉시 실행하지 않고 임시공간에 저장해두고 바로 사용자에게 결과를 반환해서 성능 향상을 시킨다 이 때 사용하는 임시 메모리 공간이다.
- 단, 응답 전에 중복여부가 확인되어야 하는 unique index는 change buffer를 사용할 수없다.
- Change Buffer 에 기록된 인덱스 레코드 조각은 background 스레드에 의해 병합된다. 이 때 스레드를 change buffer merge thread라고 한다.
- `innodb_change_buffering` 변수로 어떤 작업에 대해 change buffer 를 쓰게 할 것인지 결정할 수 있다. 

### 3-7. Adaptive Hash Index
- 일반적으로 MySQL에서의 인덱스는 모두 B- Tree 자료구조로 관리된다.
- Adaptive Hash Index는 b-Tree의 검색 시간을 줄여주기 위해 도입되었다. 자주 읽히는 데이터 페이지의 키값을 통해 해시 인덱스를 만들고, 필요할 때마다 Adaptive Hash Index를 통해 페이지에 즉시 접근 가능하도록 한다. 이 방식은 Hash table이기 때문에 O(1)으로 수행되므로, B-Tree의 Log2(N)보다 빠르고 그만큼 Cpu자원을 아낄 수 있다.
- 단, 다음과 같은 경우 Adaptive Hash Index는 성능 향상이 크지 않다.
    - 디스크 읽기가 많은 경우
    - 패턴 쿼리가 많은경우 (LIKE문)
    - 큰 테이블에 대해 스캔 범위가 넓은 경우
- 다음 경우에는 큰 이득을 볼 수 있다.
    - 디스크의 데이터가 InnoDB 버퍼 풀 크기와 비슷할 때
    - equals 검색이 많은 경우(==, in절)
    - 쿼리의 데이터가 일부 데이터만 조회하는 것이 대부분인 경우

---

## 4. Indexing

### 4-1. 데이터베이스 처리 단위 - page

#### 4-1-1. DB의 처리 단위

![image](https://user-images.githubusercontent.com/92377162/235340379-12a15aac-aa2c-4a39-bccd-e5d4d23b780f.png)

- MySQL에서 조회하는 데이터는 InnoDB Buffer pool에 있어야 한다. 이미 있지 않은 데이터라면, Disk에서 읽어서 메모리에 올려놓은 뒤에 응답한다.
- Disk에서 데이터를 읽을 때는 원하는 데이터만 읽어서 메모리에 올리지 않는다. 내가 원하는 데이터가 속한 **page 단위로 읽어서 메모리에 로드** 한다.
- 위 예제에서 `select * from EMP where id = 1` 로 조회했다고 하더라도, 1과 2가 같은 페이지에 속한다면, 1,2가 모두 메모리에 올라가게 된다.
- 메모리는 Disk보다 공간의 제약이 있다. 사용하지 않는 데이터는 메모리에서 삭제해야하는데, 이때도 page 단위로 삭제된다.
- 따라서 page의 크기가 데이터베이스의 성능에 큰 영향을 미친다. 다음과 같은 상황은 어떤 결과를 낳을까?
    1. page의 크기가 너무 크다면?
    2. page의 크기가 너무 작다면?

- MySQL의 page는 16KB 단위로 관리한다.
- Oracle은 block이라는 단위로 관리하는데, 그 크기를 조정할 수 있다. 2^N으로 최대 64KB까지 가능하다.

#### 4-1-2. Disk와 Memory의 page관계

![image](https://user-images.githubusercontent.com/92377162/235340532-ad71f57c-d3e7-4136-bf1d-68f45e98cf33.png)

- RDBMS는 row단위로 조회한다, Query에서 원하는 column을 따로 명시했다고 하더라도, 실제로 디스크에서 일치하는 row를 찾으면 해당 row 전체가 같은 page 에 있으므로 함께 로드된다.

#### 4-1-3. Page의 크기와 record의 관계
- 각 테이블의 row 사이즈에 따라서 1개의 page 에 있는 row의 수가 다르다. 만약, 하나의 row가 16KB 이상이라면 2개의 page에 나눠서 저장된다.

    ![image](https://user-images.githubusercontent.com/92377162/235340571-a531c57a-b21f-4f1f-9aed-e42d449a291a.png)

- 테이블 설정이 다음과 같다면 어떻게 될까?

    ```SQL
    NAME: varchar(100),
    DEPT: char(10),
    DESC1: varchar(4000),
    DESC2: varchar(4000),
    DESC3: varchar(4000),
    DESC4: varchar(4000),
    BINARY1: BLOB,
    BINARY2: BLOB
    ```

- 따라서 page 가 너무 크다면, 필요한 데이터에 비해서 Memory에 많은 데이터가 올라오므로 cache hit가 떨어진다. 그리고 메모리를 불필요하게 많이 점유하게 된다.
- 반대로 page 가 너무 작다면, 데이터마다 page 를 너무 빈번하게 메모리에 로드하고 삭제하게 된다. 이 과정에서 cache hit 또한 떨어지고, 추가삭제 작업 때문에 cpu 자원을 많이 소모하게 된다.

### 4-2. Index의 구조와 동작방식(B-Tree)

#### 4-2-1. B-Tree의 검색 방식

![image](https://user-images.githubusercontent.com/92377162/235340723-e0a1cf5f-3a02-4a51-b6bd-9b3a763ae05b.png)

- 위 tree 에서 Joey 를 찾는다고 해보자 어떤 과정으로 찾을까?
    - Root 블록에서 검색하려는 단어의 앞자부터 일치하는 범위를 찾는다.
        - [Anna, Janna) 범위의 알파벳은 BB_1 부터 다음 검색
        - [Janna, ) 범위의 알파벳은 BB_2 부터 다음 검색
    - Branch Block에서 같은 방식으로 찾는 대상이 속한 범위의 leaf block을 찾는다.
    - Leaf Block 안에서 해당하는 문자열을 찾는다.
- **Leaf block까지 도달하는 과정**을 `수직적 탐색` 이라고 한다.
- **Leaf block에서 레코드를 찾는 과정**을 `수평적 탐색` 이라고 한다.

#### 4-2-2. B-Tree index가 비효율적일 때
- B-Tree는 수직 탐색의 비용이 크다. Leaf block을 찾는다면, 해당 블록내에서 찾는 수평적 탐색은 블록내의 크기 자체가 작기 때문에 비용이 크지 않다.
- 수직적 탐색은 depth가 깊을수록 시간이 오래걸린다. 그렇다면 언제 depth가 깊어질까?
    - 데이터의 양 자체가 많을때 Tree 의 깊이 자체가 깊어진다.
- 기본적으로 인덱스를 구성하는 데이터도 페이지 단위로 관리된다. 데이터의 길이가 길다면 더 많은 페이지가 필요하다. 데이터의 길이가 길다면, depth가 깊어질 뿐만 아니라 메모리에 로드되는 페이지도 더 많아진다. 

### 4-3. 결합 인덱스

#### 4-3-1. 결합 인덱스란
- 결합 인덱스는 두 개 이상의 컬럼으로 index를 구성하는 경우를 말한다.
    - 순서에 따라 선행 컬럼, 후행 컬럼으로 구분한다.
    - 선행 컬럼에서 같은 값을 가진 경우, 후행 컬럼으로 정렬한다.
    - 따라서 선행, 후행의 순서가 성능에 큰 영향을 미친다. 

    ![image](https://user-images.githubusercontent.com/92377162/235341068-86a01cdd-d4b7-4d30-9a76-0f7005c7ccb4.png)

#### 4-3-2. 결합인덱스의 원리 - 순서의 중요성
- 위의 INDEX_2 에서
    - Q: 서울에 사는 김기사를 찾는다면 어떻게 될까?
    - Q: 김기사를 찾는다면 어떻게 될까?

- 서울에 사는 김기사
    - `WHERE location = ‘Seoul’ and name = ‘김기사’`
        - location먼저 찾고, seoul 안에서 정렬된 이름으로 검색

- 김기사
    - `WHERE name = ‘김기사’`
        - location을 알 수 없으므로, 모든 location에 대해 김기사를 검색
        - 정렬이 안된 것이랑 같음
            - TABLE FULL SCAN

- Q: 같은 검색조건을 `INDEX[ name + location]` 으로 구성된 테이블에 검색한다면, 결과는 어떻게 달라질까?

#### 4-3-3. 결합인덱스의 원리 - 정렬

![image](https://user-images.githubusercontent.com/92377162/235341282-8008e930-e22e-460e-9e94-a7fe745d27af.png)

```SQL
SELECT location, name, register_date FROM driver WHERE location='Seoul' and name = '김기사' ORDER BY register_date;
```

- Q: INDEX2 로 구성된 테이블에 위 쿼리를 수행하면 어떻게 될까?
- Q: INDEX3 으로 구성된 테이블에 위 쿼리를 수행하면 어떻게 될까?

- INDEX2
    - register_date 가 정렬되어있지 않으므로, client 의 sort buffer 에 해당 내용을 적재 후, 정렬을 한 뒤 내보내게 된다.
- INDEX3
    - reigster_date 로 이미 정렬되어있으므로, 그 인덱스에서 조회된 그 상태로 client 에게 전달된다.

#### 4-3-4. Covering Index

![image](https://user-images.githubusercontent.com/92377162/235341411-7587224d-b0e7-4b7a-8053-a71749eae184.png)

```SQL
SELECT location, register_date, name FROM driver WHERE location='Busan' and register_date > '20120101';
```

- Q: 위 쿼리를 INDEX4 에 수행하면 어떤 동작을 할까?
- Q: 위 쿼리를 INDEX 5에 수행하면 어떤 동작을 할까?

- INDEX4의 경우, name 정보가 index에 없으므로 테이블에서 name정보를 추가로 가져와야 한다.
- INDEX5의 경우, name정보가 index에 있으므로 바로 응답이 가능하다.

- Q: 그렇다면 INDEX를 가능한한 많이 거는 것이 좋을까?

#### 4-3-5. 결합 인덱스 가이드
1. 조건절에 자주 사용되는 컬럼들을 선정한다.
2. 선정된 컬럼 중 equals 조건(=, in)으로 조회되는 컬럼을 선행 컬럼으로 한다.
3. Sort 작업이 생략되도록 sort 기준이 있다면 해당 컬럼을 인덱스에 추가한다.
4. Covering Index로 해결할 수 있다면 해당 컬럼을 인덱스에 추가한다.
    a. 실행 계획에 Using index 로 마킹된다.

### 4-4. Index Scan의 종류

#### 4-4-1. Index Range Scan
- INDEX 루트 블록에서 리프 블록까지 수직적으로 탐색한 후에 리프 블록을 필요한 범위만 스캔하는 방식
- Single Block I/O

##### 4-4-2. Index Range Scan Descending
- INDEX Range Scan과 기본적으로 동일하지만, INDEX를 뒤에서부터 앞쪽으로 스캔
- Single Block I/O

#### 4-4-3 Index Unique Scan
- 수직적 탐색만으로 데이터를 찾음
- Unique INDEX를 ‘=‘ 조건으로 탐색하는 경우에 작동
- Single Block I/O

#### 4-4-4. INDEX Skip Scan
- 루트 또는 브랜치 블록에서 읽은 칼럼값 정보를 보고 조건에 부합하는 레코드를 포함 할 가능성이 있는 하위 블록만 골라서 액세스
- 결합 칼럼 index 구성에서 선행 컬럼에 조건이 없는 경우
- 선행 컬럼의 cardinality가 작을 때 효과적

#### 4-4-5. INDEX Full Scan
- INDEX 리프 블록을 처음부터 끝까지 수평적으로 탐색하는 방식
- Single Block I/O
- Index Leaf Node Entry의 정렬된 결과를 받음

#### 4-4-6. INDEX Fast Full Scan
- INDEX 세그먼트 전체를 Multiblock Read 방식으로 스캔
- INDEX의 논리 구조가 아니라, 물리적인 저장순서대로 INDEX블록을 읽음
- Multiblock I/O 발생
    - `db_file_multiblock_read_count`로 설정
- 결과의 **정렬 순서가 보장되지 않는다.**

---

## 5. MySQL High Availability

### 5-1. HA란

#### 5-1-1. HA란
- 일반적인 의미로는 서비스 또는 시스템이 약속한 수준의 서비스를 이용가능한 상태를 유지하는 것을 말한다.
- Database의 경우 SPOF 없이 비정기적인 HW 장애에도 불구하고 항상 이용할 수 있는 상태(ACID)를 유지할 수 있는 아키텍처, 시스템의 구성을 말한다.
    - replication: 데이터의 유실을 방지하기 위한 목적으로 복제 기능만을 말하는 국소적인 의미.

#### 5.1.2. HA의 필요성
- Database는 데이터의 중앙 저장소이다. 데이터를 활용할 수 없다면 서비스를 이용할 수 없다는 것이나 마찬가지이다.
- Database 는 대량의 데이터 처리 작업을 할 수 있다. 데이터베이스에 장애가 나면 대량의 워크로드를 처리할 수 없는 상태가 된다.
- 따라서 데이터베이스는 사실상 무중단 운영이 필요하다. 하지만 데이터베이스의 용도 자체가 대량의 데이터를 저장하고, 고성능이 필요한 워크로드를 처리하다보니 장애에 취약하다. 클라이언트의 잘못된 사용으로 장애가 날 수도 있고, 데이터나 메모리 용량을 관리하지 못해 장애가 나기도 한다. 예상치 못한 HW장비의 문제로 장애가 나는 것은 예측을 할 수도 없다.
- Data를 언제나 두벌 저장하면 되지 않을까? 이것은 Application 개발자에게 Database의 책임을 떠넘기는 것이다. 여기서 발생하는 코스트, 복잡도, 장애는 예측이 불가능하고, 관리되지 않는다. 따라서 Database 자체에서 장애에도 무중단 운영을 위한 기능이 필요하다. 이것을 Database HA라고 한다.

#### 5-1-3. HA의 목표
1. SPOF(single point of failure)의 제거
2. Detection of failure: 장애 인지를 실시간으로 확인할 수 있어야 한다.
3. Reliable crossover: 장애 방지를 위해 자동으로 전환하는 시스템이 필요.

### 5-2. MMM
- Multi-Master replication Manager 의 줄임말.
- Perl 기반의 auto failover 기능을 하는 오픈소스이다.

#### 5-2-1. MMM 구조

![image](https://user-images.githubusercontent.com/92377162/235341699-cf2d21ac-0382-4e3e-b4a5-368aa0d560bd.png)

- MMM Monitor와의 관계
    - DB 서버에서 agent를 실행시키고, 별도로 구성한 MMM monitor 서버와 통신을 하면서 MMM monitor 서버에 의해 상태 판단(health check)과, failover 전략을 수행한다.

- master(active, standby), slave
    - active master와 standby master 가 있다.
    - VIP는 active master 에만 연결한다.
    - active master 는 사용하는 서버, standby master는 active. master 와 연결해서 양방향 복제를 한다.
    - Slave 를 추가하면, 단방향 복제를 하는 slave 가 하나씩 추가된다. 
    - slave는 언제나 read only mode이다.

#### 5-2-2. MMM Failover

![image](https://user-images.githubusercontent.com/92377162/235341766-ce760e4e-495b-40db-9897-10256f6ec96a.png)

- active master 에 장애가 나면
    1. active master 는 master 의 역할을 잃는다.
        a. read only 로 변경
        b. 존재하는 session kill
        c. VIP 회수
    2. master standby 또는 slave로 복제를 재구성한다.
        a. 복제지연이 있는지 확인한다.
        b. standby master 를 기준으로 복제를 맞춘다.
    3. master standby 에 대한 readonly 모드를 해제하고 VIP를 할당한다.

#### 5-2-3. MMM 의 한계
- Multi slave 환경에서 복제 Crash 가능성이 존재한다.
    - insert 도중 active master 에서 장애 발생
    - slave는 복제를 받았는데, standby master 가 복제를 못받음.
    - standby master 가 active master 로 전환
    - 다시 active master 에 insert를 하면 slave 에서 복제 에러

### 5-3. MHA
- Perl 기반의 Auto failover opensource이다. MMM과는 다르게 agentless 방식이다.

#### 5-3-1. MHA 구성

![image](https://user-images.githubusercontent.com/92377162/235341834-687d3b9f-7f90-4955-948f-128db75dbae0.png)

- 하나의 master 와 다수의 slave 로 구성된다.
- master와 slave 사이에 서로의 연결을 구성하고 상태를 확인한다.
- 모두 단방향 복제이다.

#### 5-3-2. MHA의 failover

![image](https://user-images.githubusercontent.com/92377162/235341868-a2c1ec1f-aa25-4d90-a5e1-5ce0a58bba5b.png)

- master 에 장애가 나면
    1. master 와 slave 의 복제 연결을 끊는다.
    2. 나머지 slave DB들로 복제 연결을 재구성한다.
    3. 가장 최신의 데이터를 가지고 있는 DB를 마스터로 전환한다.

- MHA는 MMM의 복제 crash를 방지하기위해
    - 복제 대상을 구분한다: 바이너리 로그, 릴레이 로그 파일을 읽는다.
    - 바이너리로, 릴레이로그를 비교한 후 diff 를 추출한다.
    - diff 가 반영이 안된 slave 노드에 해당 diff를 적용한다.

### 5-4. Cloud, Third party solution
- MMM 또는 MHA 아키텍처를 직접 구성하고, 유지보수하는 일은 쉽지 않다.
- AWS, Azure 등 대형 Cloud 업체에서는 서비스 형태로 간단한 설정만으로도 HA를 구성할 수 있도록 한다. 당연히 HA를 구성하기위한 추가 인프라에 서비스 비용이 추가되어 비용은 커진다. 하지만, 숙련되지 않은 엔지니어 또는 전문 DBA가 아닌 다른 데이터 업무를 하면서 DB를 production level로 관리하는 것은 쉬운일이 아니다.
- 따라서 기회비용을 고려해서 빠르고 안전하게 솔루션을 사용하는 것도 하나의 방법이다.
- 설치형 솔루션도 존재하는데, 이 경우 인프라에 대한 관리와 솔루션에 대한 사용이 분리된다는 점이 단점이다.

#### 5-4-1. AWS의 multi master MySQL Aurora
- https://aws.amazon.com/ko/blogs/database/building-highly-available-mysql-applications-using-amazon-aurora-mmsr/

#### 5-4-2. Azure 의 MySQL HA
- https://learn.microsoft.com/en-us/azure/mysql/single-server/concepts-high-availability
- https://learn.microsoft.com/en-us/azure/mysql/flexible-server/concepts-high-availability
